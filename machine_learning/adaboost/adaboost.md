# adaboost

集成方法通过组合多个分类器的分类结果，获得了比简单的单分类器更好的分类结果。 adaboost 是利用同一类分类器的集成方法。  
多个分类器组合可能会进一步凸显出当个分类器的不足，比如说过拟合问题。如果分类器之间差别显著，那么多个分类器的组合可能会缓解这一问题。分类器之间的差别可以是算法的本身或者是应用于算法上的数据的不同。   


有两种集成方法，bagging 和boosting。bagging 是从原始数据集选择S次后得到S个新数据集的一种技术。新数据集和原始数据集大小相等，每个数据集都是通过在原始数据集中随机选择一个样本进行替换而得到的。而boosting 在bagging 的思路上更进了一步，它在数据集上应用了多个不同的分类器。另一个成功的集成方法是随机森林。  

adaboost 方法以弱学习器作为基础分类器。并且输入数据，使其通过权重向量进行加权。在第一次迭代中，所有的数据权重都相等，但是在后续迭代中，前次迭代中分错的数据的权重会增大，这种针对错误的调节能力正式adaboost 的长处。
